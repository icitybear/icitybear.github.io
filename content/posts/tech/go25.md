---
title: "go锁-单机锁Sync.Mutex和读写锁Sync.RWMutex" #标题
date: 2023-09-01T17:46:37+08:00 #创建时间
lastmod: 2023-09-01T17:46:37+08:00 #更新时间
author: ["citybear"] #作者
categories: # 没有分类界面可以不填写
- tech
tags: # 标签
- go进阶
- go源码
keywords: 
- 
description: "" #描述 每个文章内容前面的展示描述
weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序
slug: ""
draft: false # 是否为草稿
comments: true #是否展示评论 有自带的扩展成twikoo
showToc: true # 显示目录 文章侧边栏toc目录
TocOpen: true # 自动展开目录
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
disableShare: true # 底部不显示分享栏
showbreadcrumbs: true #顶部显示当前路径
cover:
    image: "" #图片路径：posts/tech/文章1/picture.png
    caption: "" #图片底部描述
    alt: ""
    relative: false

# reward: true # 打赏
mermaid: true #自己加的是否开启mermaid
---

# 概念
- 竞态条件:一旦数据被多个线程共享，那么就很可能会产生争用和冲突的情况，这种情况也被称为竞态条件（race condition），这往往会破坏共享数据的一致性。
- 共享资源: 数据块和代码块的背后都隐含着一种或多种资源（比如存储资源、计算资源、I/O 资源、网络资源等等），所以我们可以把它们看做是共享资源
- 临界区:只要一个代码片段需要实现对共享资源的串行化访问，就可以被视为一个临界区（critical section）

临界区总是需要通过同步机制进行保护的，否则就会产生竞态条件，导致数据不一致

同步工具最常用的互斥量（mutual exclusion，简称 mutex），sync 包中的 Mutex 就是与其对应的类型，该类型的值可以被称为互斥锁

Go 协程在执行临界区中的代码时，不被其他的协程打扰，实现串行执行 (了解中断与原子操作)

- 线程同步和互斥是多线程编程中的两个重要概念，它们都是为了解决多线程环境下的资源共享和访问问题。
  - **线程同步**线程同步是指多个线程按照一定的顺序执行，以确保在访问共享资源时，不会出现数据不一致的问题。同步机制主要包括条件变量和信号量。
  - **线程互斥**线程互斥是指在同一时刻，只允许一个线程访问共享资源，以防止数据不一致和竞争条件。互斥锁是实现线程互斥的主要工具。

- 在操作系统中，锁、条件变量和信号量都是用来实现线程同步与互斥的机制。
  - 锁（Lock）是一种互斥量，用于保护共享资源，防止多个线程同时访问。当一个线程获得锁时，其他线程必须等待该线程释放锁后才能访问共享资源。常见的锁包括互斥锁和读写锁。
  - 条件变量（Condition Variable）是一种线程间通信的机制，用于等待某个条件的发生。当一个线程等待某个条件时，它会阻塞并释放锁，直到另一个线程发出信号通知该条件已经满足，该线程才会被唤醒并重新获得锁。
  - 信号量（Semaphore）是一种计数器用于控制多个线程对共享资源的访问。当一个线程访问共享资源时它会尝试获取信号量，如果号量的值大于 0，则该线程可以访问共享资源并将信号量的值减 1；如果信号量的值等于 0，则该线程必须等待其他线程释放信号量后才能访问共享资源。

## 互斥锁
**在 Go 中，sync.Mutex 是互斥锁的实现。**它有两个方法：Lock 和 Unlock，用于控制互斥锁的状态。sync.Mutex 的底层实现是基于操作系统提供的 futex（fast userspace mutex）机制，它使得线程在获取锁时可以避免进入内核态，并且能够更加高效地进行线程上下文切换。这使得 Go 中的互斥锁在资源竞争较小、并发度较高的情况下有着良好的性能表现。

## 条件变量
**在golang中，使用sync.Cond可以实现条件变量。**func (c Cond) Wait()阻塞等待条件变量满足，释放已掌握的互斥锁相当于cond.L.Unlock()。 注意：两步为一个原子操作。当被唤醒，Wait()函数返回时，解除阻塞并重新获取互斥锁。相当于cond.L.Lock() func (c *Cond) Signal()：单发通知，给一个正等待（阻塞）在该条件变量上的goroutine（线程）发送通知【一般都使用这个】



# 一把锁最简单纯粹的主干流程：上锁/解锁

• 通过 Mutex 内一个状态值标识锁的状态，例如，取 0 表示未加锁，1 表示已加锁；

• 上锁：把 0 改为 1；

• 解锁：把 1 置为 0.

• 上锁时，假若已经是 1，则上锁失败，需要等他人解锁，将状态改为 0.

# 由自旋到阻塞的升级过程
一个优先的工具需要具备探测并适应环境，从而采取不同对策因地制宜的能力.

针对 goroutine 加锁时发现锁已被抢占的这种情形，此时摆在面前的策略有如下两种：

• 阻塞/唤醒：将当前 goroutine 阻塞挂起，直到锁被释放后，以回调的方式将阻塞 goroutine 重新唤醒，进行锁争夺；

• 自旋 + CAS：基于自旋结合 CAS 的方式，重复校验锁的状态并尝试获取锁，始终把主动权握在手中.
- 适用的场景：
|锁竞争方案|	优势	|劣势	|适用场景|
|:--|:--|:--|:--|
|阻塞/唤醒	|精准打击，不浪费 CPU 时间片	|需要挂起协程，进行上下文切换，操作较重	|并发竞争激烈的场景|
|自旋+CAS	|无需阻塞协程，短期来看操作较轻	|长时间争而不得，会浪费 CPU 时间片	|并发竞争强度低的场景|

## sync.Mutex 
- 结合两种方案的使用场景，制定了一个锁升级的过程，<font color="red">反映了面对并发环境通过持续试探逐渐由乐观逐渐转为悲观的态度</font>，具体方案如下：

1. 首先保持乐观，goroutine 采用自旋 + CAS 的策略争夺锁；
2. <font color="red">尝试持续受挫达到一定条件后，判定当前过于激烈，则由自旋转为 阻塞/挂起模式</font>
    - 自旋累计达到 4 次仍未取得战果；
    - CPU 单核或仅有单个 P 调度器；（此时自旋，其他 goroutine 根本没机会释放锁，自旋纯属空转）；
    - 当前 P 的执行队列中仍有待执行的 G. （避免因自旋影响到 GMP 调度效率）.

## sync.Mutex 正常模式和饥饿模式
- 正常模式/非饥饿模式：这是 sync.Mutex 默认采用的模式. 当有 goroutine 从阻塞队列被唤醒时，会和此时先进入抢锁流程的 goroutine 进行锁资源的争夺，假如抢锁失败，会重新回到阻塞队列头部.
  - <font color="red">（值得一提的是，此时被唤醒的老 goroutine 相比新 goroutine 是处于劣势地位，因为新 goroutine 已经在占用 CPU 时间片，且新 goroutine 可能存在多个，从而形成多对一的人数优势，因此形势对老 goroutine 不利.）</font>
- 饥饿模式：这是 sync.Mutex 为拯救陷入饥荒的老 goroutine 而启用的特殊机制，饥饿模式下，锁的所有权按照阻塞队列的顺序进行依次传递. 新 goroutine 进行流程时不得抢锁，而是进入队列尾部排队.（将抢锁流程由非公平机制转为公平机制）
  - 饥饿：顾名思义，是因为非公平机制的原因，导致 Mutex 阻塞队列中存在 goroutine 长时间取不到锁，从而陷入饥荒状态；

## 两种模式的转换条件：
1. 默认为正常模式；
2. 正常模式 -> 饥饿模式：<font color="red">当阻塞队列存在 goroutine 等锁超过 1ms 而不得</font>，则进入饥饿模式；
3. 饥饿模式 -> 正常模式：<font color="red">当阻塞队列已清空</font>，或取得锁的 goroutine 等锁时间已低于 1ms 时，则回到正常模式.
- 两种模式的切换体现了 sync.Mutex 为适应环境变化，在公平与性能之间做出的调整与权衡. 回头观望，这一项因地制宜、随机应变的能力正是许多优秀工具所共有的特质.

# goroutine 唤醒标识
为尽可能缓解竞争压力和性能损耗，sync.Mutex 会不遗余力在可控范围内减少一些无意义的并发竞争和操作损耗.

在实现上，sync.Mutex <font color="red">通过一个 mutexWoken 标识位，标志出当前是否已有 goroutine 在自旋抢锁或存在 goroutine 从阻塞队列中被唤醒；</font> 倘若 mutexWoken 为 true，且此时有解锁动作发生时，就没必要再额外唤醒阻塞的 goroutine 从而引起竞争内耗.

# 相关流程图
## Mutex.state 锁状态 数据结构
![Alt text](image1.png)

• state & mutexLocked：判断是否上锁；

• state | mutexLocked：加锁；|=

• state & mutexWoken：判断是否存在抢锁的协程；

• state | mutexWoken：更新状态，标识存在抢锁的协程；|=

• state = state &^ mutexWoken：更新状态，标识不存在抢锁的协程；(右侧第2个bit位)

(&^ 是一种较少见的位操作符，以 x &^ y 为例，假如 y = 1，结果为 0；假若 y = 0，结果为 x)

• state & mutexStarving：判断是否处于饥饿模式；

• state | mutexStarving：置为饥饿模式；|=

• state >> mutexWaiterShif：获取阻塞等待的协程数；

• state += 1 << mutexWaiterShif：阻塞等待的协程数 + 1 (1先左移3位)

## 加锁 
### Lock()
![Alt text](image2.png)

### lockSlow()
#### 自旋空转
- 旧state值已上锁,并且未进入饥饿模式,且可以自旋,进入自旋抢锁逻辑
![Alt text](image3.png)

#### state 新值构造
- 自旋抢锁失败后处理 (锁自由，饥饿模式，未满足自旋转条件（轮次够了）)
![Alt text](image4.png)

#### state 新值替换

##### 上锁成功
- 前面 可能存在锁自由，未满足自旋转条件 的尝试加锁, 到底有没有真正成功; 旧值是正常模式未上锁

##### 阻塞挂起
1. 正常模式抢锁失败，
2. 锁已处于饥饿模式，而当前 goroutine 不是从阻塞队列被唤起的协程

- 基于 queueLifo 标识当前 goroutine 是从阻塞队列被唤起的老客还是新进流程的新客

##### 从阻塞态被唤醒
- 当前 goroutine 是从 Mutex 的阻塞队列中被唤起的
- 锁是饥饿模式，当前 goroutine 无需竞争可以直接获得锁；
  - 等锁时间小于1ms(当前协程不是饥饿状态)或者阻塞队列只剩下我一个, 将 Mutex.state 置为正常模式
  - 通过 delta 变量记录差值，最终通过原子操作添加到 Mutex.state 中；
- 锁是正常模式, 重置自旋技数，尝试抢锁变更局部变量awoke

## 解锁

### Unlock()
![Alt text](image9.png)

### unlockSlow(new)
![Alt text](image10.png)
- runtime_Semrelease(s *uint32, handoff bool, skipframes int),唤醒阻塞队列,参数handoff若为true，则让被唤醒的g立刻继承当前g的时间片继续执行。若handoff为false，则把刚被唤醒的g放到当前p的runq中(参与竞争)。

# 源码
``` go

package sync

import (
	"internal/race"
	"sync/atomic"
	"unsafe"
)

// Provided by runtime via linkname.
func throw(string)
func fatal(string)

// tag: 锁结构体
type Mutex struct {
	state int32  // 第1-3位，4-32
	sema  uint32 // 信号量 用于阻塞和唤醒 goroutine 的信号量
}

// A Locker represents an object that can be locked and unlocked.
type Locker interface {
	Lock()
	Unlock()
}

// tag: 状态位
const (
	mutexLocked      = 1 << iota // 1左移0位（1） mutex is locked 上锁 1 state右侧的第一个 bit位标志是否上锁，0-未上锁，1-已上锁；
	mutexWoken                   // 1左移1位 2 state右侧的第二个bit位标 是否有唤醒的在抢占 是否有 goroutine 从阻塞中被唤醒，0-没有，1-有；
	mutexStarving                // 1左移2位 4 state右侧的第三个bit位标 饥渴状态
	mutexWaiterShift = iota      // iota=3 用来移位3位

	starvationThresholdNs = 1e6 // 1nm，自旋超过时间阀值就从正常模式切换到饥渴模式
)

// 上锁
func (m *Mutex) Lock() {
	//tag: 首先直接尝试cas上锁
	// state=0, 表示没有阻塞的协程，标志位都是0，正常模式，无协程取锁，未上锁
	if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {
		if race.Enabled {
			race.Acquire(unsafe.Pointer(m))
		}
		return
	}

	//已经有上锁的，协程进入慢锁流程
	m.lockSlow()
}


func (m *Mutex) TryLock() bool {
	old := m.state
	if old&(mutexLocked|mutexStarving) != 0 {
		return false
	}

	if !atomic.CompareAndSwapInt32(&m.state, old, old|mutexLocked) {
		return false
	}

	if race.Enabled {
		race.Acquire(unsafe.Pointer(m))
	}
	return true
}

// 慢锁流程
func (m *Mutex) lockSlow() {
	var waitStartTime int64 // 标识当前 goroutine 在抢锁过程中的等待时长，单位：ns 挂起前记录，唤醒后的时间记录 差值
	starving := false       // 标识当前是否处于饥饿模式
	awoke := false          // 标识当前是否已有协程在等锁
	iter := 0               // 标识当前 goroutine 参与自旋的次数，用来判断锁升级
	old := m.state          // 临时存储锁的 state 值，旧值
	// tag: 自旋+cas
	for {
		// tag: 旧state值已上锁且正常模式且可以自旋,进入自旋抢锁逻辑
		// old &  0000....101 == 0000....001 所以old 是只有 0000....0x1
		// runtime_canSpin 是否可自旋
        // 自旋次数达到上限，再进入下一步。需要注意的是，如果这是一个被唤醒的协程，还需要将唤醒标志位置成唤醒状态1
		if old&(mutexLocked|mutexStarving) == mutexLocked && runtime_canSpin(iter) {

			// tag: 进入if分支，old>>mutexWaiterShift当前阻塞队列有协程，但是old&mutexWoken还未被未唤醒
			// atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) 当前自己协程就是在尝试取锁了，mutexWoken 标识置为 1，避免再有其他协程被唤醒和自己抢锁
			if !awoke && old&mutexWoken == 0 && old>>mutexWaiterShift != 0 &&
				atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) {
				// mutexWoken为了通知在解锁Unlock()中不要再唤醒其他的阻塞队列的协程
				// 局部变量awoke=1，当前自己协程就是在尝试取锁了
				awoke = true // 
			}
			// 进入自旋
			runtime_doSpin() // 核心是汇编实现,循环执行三十次PAUSE指令. 告知调度器 P 当前处于自旋模式
			iter++           // 自旋计数器
			old = m.state    // 更新state旧值 上面if有cas
			continue
		}

		// tag: 自旋抢锁失败后处理 (锁自由，饥饿模式，未满足自旋转条件（轮次够了）)
		// 从自旋中走出来后，会存在两种分支，要么加锁成功，要么陷入阻塞，不论是何种情形，都会先对 sync.Mutex 的状态新值 new 进行更新；
		new := old // old是锁当前的状态，new是期望的状态，以期于在后面的CAS操作中更改锁的状态
		// 非饥饿模式（可能存在锁自由，未满足自旋转条件（）
		if old&mutexStarving == 0 {
			// 新值 new 中置为已加锁，即尝试抢锁
			new |= mutexLocked
		}
		// 旧值为已加锁或者处于饥饿模式，则当前 goroutine 在这一轮注定无法抢锁成功
		if old&(mutexLocked|mutexStarving) != 0 {
			new += 1 << mutexWaiterShift // 新值的阻塞协程数加1；
		}

		// 当前进入饥饿模式且旧值已加锁 starving局部变量 在后面的逻辑会设置成true(进入饥饿模式)
		if starving && old&mutexLocked != 0 {
			new |= mutexStarving // 新值置为饥饿模式
		}

		// 局部变量标识是已有唤醒协程抢锁，说明 Mutex.state 中的 mutexWoken 是被当前 goroutine 置为 1 的，
		// 但由于当前 goroutine 接下来要么抢锁成功，要么被阻塞挂起，有义务在新值中将该 mutexWoken 标识更新置 0.
		// 唤醒的阻塞协程未获得锁的情况下，awoke = true 下一轮循环
        // 协程被唤醒，需要将唤醒标志位清0，因为他要么继续沉睡，要么获取锁
		if awoke {
			// The goroutine has been woken from sleep,
			// so we need to reset the flag in either case.
			if new&mutexWoken == 0 {
				throw("sync: inconsistent mutex state")
			}
			new &^= mutexWoken // 新值中将该 mutexWoken 标识更新置 0.
		}

		// tag: state 新旧值替换
		if atomic.CompareAndSwapInt32(&m.state, old, new) {
			// tag: 新值设置成功,要么加锁成功，要么挂起
			// 前面 可能存在锁自由，未满足自旋转条件 的尝试加锁, 到底有没有真正成功
			// 旧值 是正常模式且未上锁
			if old&(mutexLocked|mutexStarving) == 0 {
				break // tag: 正常模式下，加锁成功的唯一出口
			}

			// 证明当前goroutine没有获取到锁,进行挂起
			// waitStartTime != 0就证明当前goroutine之前已经等待过了，则需要将其放置在等待队列队头
			// 基于 queueLifo 标识当前 goroutine 是从阻塞队列被唤起的老客还是新进流程的新客
			queueLifo := waitStartTime != 0
			// 等待的起始时间为0，则是新客，获取第一次的时间
			if waitStartTime == 0 {
				waitStartTime = runtime_nanotime()
			}
			// 信号量上锁 阻塞等待，休眠当前goroutine等待并尝试获取信号量唤醒当前goroutine
			runtime_SemacquireMutex(&m.sema, queueLifo, 1) // 将当前协程添加到阻塞队列中，倘若是老客则挂入队头；倘若是新客，则挂入队尾

			// tag: 被信号量唤醒之后检查当前goroutine是否应该表示为饥饿
			// 这里表示为饥饿之后，会在下一轮循环中（cas state新旧值替换）尝试将锁的状态更改为饥饿模式
			// 1. 如果当前goroutine已经饥饿（在上一次循环中更改了starving为true）
			// 2. 如果当前goroutine已经等待了1ms以上
			starving = starving || runtime_nanotime()-waitStartTime > starvationThresholdNs

			old = m.state // 再次获取锁状态
			// 唤醒前，锁是饥饿模式
			if old&mutexStarving != 0 {
				// 阻塞唤醒的 锁饥饿模式下，肯定是公平模式，一定加锁成功 当前 goroutine 无需竞争可以直接获得锁；
				// 饥饿模式协程是在Unlock()时handoff到当前协程的

				// 饥饿模式下如果当前锁上锁或者被唤醒状态，或者等待队列为空,这代表锁状态产生了不一致的问题
				if old&(mutexLocked|mutexWoken) != 0 || old>>mutexWaiterShift == 0 {
					throw("sync: inconsistent mutex state")
				}
				// 通过 delta 变量记录差值，最终通过原子操作添加到 Mutex.state 中；
				delta := int32(mutexLocked - 1<<mutexWaiterShift) // 状态为 阻塞队列协程数-1，加锁
				// 等锁时间小于1ms(当前协程不是饥饿状态)或者阻塞队列只剩下我一个
				if !starving || old>>mutexWaiterShift == 1 {
					delta -= mutexStarving // 退出饥饿模式 m.state饥饿标志位置0
				}
				atomic.AddInt32(&m.state, delta) // 相加
				break                            // tag: 饥饿模式下，加锁成功的唯一出口
			}
			// 唤醒前，锁是正常模式
			awoke = true // 当前唤醒的尝试抢锁
			iter = 0     // 重置4轮自旋计数
		} else {
			// cas失败, 其他的goroutine介入，修改过state（前面的阶段）与old值不一致了, 重新赋值开启新循环,恢复最新现场
			old = m.state
		}
	}

	if race.Enabled {
		race.Acquire(unsafe.Pointer(m))
	}
}

// 解锁
func (m *Mutex) Unlock() {
	if race.Enabled {
		_ = m.state
		race.Release(unsafe.Pointer(m))
	}

	//m.state取消锁状态 减去对应标志位,返回值new代表修改后的新值
	//锁空闲有两种情况:
	//1. 所有位为0 （new值为0）,代表没有锁了, 对应Lock加锁时，尝试从0改为1（代表没其他协程了） 直接退出
	new := atomic.AddInt32(&m.state, -mutexLocked)
	if new != 0 {
		// 2. 标志位为0, waiter数量>0,还有协程在等待解锁 unlockSlow
		m.unlockSlow(new)
	}
}

func (m *Mutex) unlockSlow(new int32) {
	// 解锁时倘若发现 Mutex 此前未加锁，直接抛出 fatal 这里不用cas
	if (new+mutexLocked)&mutexLocked == 0 {
		fatal("sync: unlock of unlocked mutex")
	}

	// 解锁后的 正常模式
	if new&mutexStarving == 0 {
		old := new
		for {

			// 判断是否有义务唤起阻塞队列头部的 goroutine

			// 无阻塞队列
			// 已上锁，说明解锁后有其他协程已抢到锁，由他负责解锁后再去唤醒
			// 锁处于唤醒状态,表示有协程被唤醒, 由他抢到锁后再去唤醒
			// 饥饿模式，所有权交给了被解锁饥饿模式的waiter
			if old>>mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken|mutexStarving) != 0 {
				return
			}

			// 说明当前锁是空闲状态，但是等待队列中有waiter，且没有goroutine被唤醒

			// 要把锁的状态设置为被唤醒((接下来要唤醒的goroutine会尝试取锁))，等待队列waiter数-1
			new = (old - 1<<mutexWaiterShift) | mutexWoken
			if atomic.CompareAndSwapInt32(&m.state, old, new) {
				runtime_Semrelease(&m.sema, false, 1) // 通过信号量唤醒某一个waiter
				return
			}
			old = m.state // 失败的话,更新old信息,进入下个循环
		}
	} else {
		// 饥饿模式, 队列一个个唤醒, 唤醒等待队列队头waiter
		runtime_Semrelease(&m.sema, true, 1)
	}

	// func runtime_Semrelease(s *uint32, handoff bool, skipframes int)
	// handoff 就是传球的意思，handoff 为 false 时，仅仅唤醒等待队列中第一个协程，但是不会立马调度该协程；
	// 当 handoff 为 true 时，会立马调度被唤醒的协程，此外，当 handoff = true 时，被唤醒的协程会继承当前协程的时间片。
	// 具体例子，假设每个 goroutine 的时间片为 2ms，gorounte A 已经执行了 1ms，假设它通过 runtime_Semrelease(handoff = true) 唤醒了 goroutine B，则 goroutine B 剩余的时间片为 2 - 1 = 1ms

	// 参数handoff若为true，则让被唤醒的g立刻继承当前g的时间片继续执行。若handoff为false，则把刚被唤醒的g放到当前p的runq中(参与竞争)。
}


```

# 极端情况
1. 当某一个被挂起的协程被唤醒后才会检查并更新饥饿标志位。
2. 如果加锁的并发量很大，始终有新的协程处于自旋阶段，那拿到锁的协程在解锁时总会因为mutexWoken为真被提前return，而永远没有阻塞协程被唤醒，这样看起来锁就没法转变为饥饿状态。
3. 看起来像是某种设计缺陷，感觉在解锁的时候加一个固定多少次会尝试唤醒阻塞协程会不会更好一些呢。还是说这种极端情况下，状态转化已经不是主要矛盾了呢。类似于 gmp 中每61次调度需要清一次全局队列积压一样.

# 读写锁 Sync.RWMutex
``` go
type RWMutex struct {
	w         Mutex  // 普通互斥锁 sync.Mutex
	writerSem uint32 // 关联写锁阻塞队列的信号量, 阻塞等待写锁的队列
	readerSem uint32 // 关联读锁阻塞队列的信号量, 阻塞等待读锁的队列
	// readerCount 1 起到计数作用 2起到提醒后续的读者，有写者在尝试请求锁的作用
	// 读锁数，当前等待或者占用读锁的goroutine数量，正常情况下等于介入读锁流程的 goroutine 数量；
	// 当 goroutine 接入写锁流程时，该值为实际介入读锁流程的 goroutine 数量减 rwmutexMaxReaders
	readerCount int32 
	readerWait  int32 // 读等待锁数，当前 goroutine 获取写锁前，还需要等待多少个 goroutine 释放读锁(占用中的)
}

const rwmutexMaxReaders = 1 << 30 // 共享读锁的 goroutine 数量上限，值为 2^29；

```

- 从逻辑上，可以把 RWMutex 理解为一把读锁加一把写锁；
- 写锁具有严格的排他性，当其被占用，其他试图取写锁或者读锁的 goroutine 均阻塞；
- 读锁具有有限的共享性，当其被占用，试图取写锁的 goroutine 会阻塞，试图取读锁的 goroutine 可与当前 goroutine 共享读锁；
- RWMutex 适用于读多写少的场景，最理想化的情况，当所有操作均使用读锁，则可实现无锁化；最悲观的情况，倘若所有操作均使用写锁，则 RWMutex 退化为普通的 Mutex.
- 竞争读锁的 goroutine 更具备优势, 存在后到读者先于写者执行（多个写锁，多个读锁）

## 读锁加锁
![Alt text](image11.png)

## 读锁解锁
![Alt text](image12.png)

## 写锁加锁
![Alt text](image13.png)

## 写锁解锁
![Alt text](image14.png)

## 读写锁源码
``` go

package sync

import (
	"internal/race"
	"sync/atomic"
	"unsafe"
)

// tag: 读写锁数据结构
type RWMutex struct {
	w         Mutex  // 普通互斥锁 sync.Mutex
	writerSem uint32 // 关联写锁阻塞队列的信号量
	readerSem uint32 // 关联读锁阻塞队列的信号量
	// readerCount 1 起到计数作用 2起到提醒后续的读者，有写者在尝试请求锁的作用
	readerCount int32 // tag: 读锁数，当前等待或者占用读锁的goroutine数量，正常情况下等于介入读锁流程的 goroutine 数量；当 goroutine 接入写锁流程时，该值为实际介入读锁流程的 goroutine 数量减 rwmutexMaxReaders
	readerWait  int32 // 读等待锁数，当前 goroutine 获取写锁前，还需要等待多少个 goroutine 释放读锁(占用中的)
}

const rwmutexMaxReaders = 1 << 30 // 共享读锁的 goroutine 数量上限，值为 2^29；

// 读者加锁
func (rw *RWMutex) RLock() {
	if race.Enabled {
		_ = rw.w.state
		race.Disable()
	}
	// 占用或等待读锁的 goroutine 数加一
	if atomic.AddInt32(&rw.readerCount, 1) < 0 {
		// tag: 当前读者到来前，已经有写者到来 写者会将readerCount - rwmutexMaxReaders
		// 说明有 goroutine 未释放写锁，因此将当前 goroutine 添加到读锁的阻塞队列中并阻塞挂起.
		runtime_SemacquireMutex(&rw.readerSem, false, 0)
	}
	if race.Enabled {
		race.Enable()
		race.Acquire(unsafe.Pointer(&rw.readerSem))
	}
}


func (rw *RWMutex) TryRLock() bool {
	if race.Enabled {
		_ = rw.w.state
		race.Disable()
	}
	for {
		c := atomic.LoadInt32(&rw.readerCount)
		if c < 0 {
			if race.Enabled {
				race.Enable()
			}
			return false
		}
		if atomic.CompareAndSwapInt32(&rw.readerCount, c, c+1) {
			if race.Enabled {
				race.Enable()
				race.Acquire(unsafe.Pointer(&rw.readerSem))
			}
			return true
		}
	}
}

// 读者解锁
func (rw *RWMutex) RUnlock() {
	if race.Enabled {
		_ = rw.w.state
		race.ReleaseMerge(unsafe.Pointer(&rw.writerSem))
		race.Disable()
	}
	// 占用或等待读锁的 goroutine 数减一；
	if r := atomic.AddInt32(&rw.readerCount, -1); r < 0 {
		// tag: 新值小于 0，说明有 goroutine 在等待获取写锁, 读者有义务去唤醒阻塞的写锁
		rw.rUnlockSlow(r)
	}

	if race.Enabled {
		race.Enable()
	}
}

// 读者慢解锁
func (rw *RWMutex) rUnlockSlow(r int32) {
	// 发现当前协程此前未抢占过读锁，或者介入读锁流程的 goroutine 数量达到上限，则抛出 fatal；
	// 1. 有读者的话 之前的值 > 0，不可能为0, 要么此前未加过读锁，要么介入读锁流程的 goroutine 数量达到上限
	// 2. 说明此时有 goroutine 介入写锁流程，但当前此前未加过读锁
	if r+1 == 0 || r+1 == -rwmutexMaxReaders {
		race.Enable()
		fatal("sync: RUnlock of unlocked RWMutex")
	}
	// tag: readerWait 写锁加锁时增加，读锁解锁时减少
	// 占用读锁-1
	if atomic.AddInt32(&rw.readerWait, -1) == 0 {
		// tag: 新值为 0，说明当前 goroutine 是最后一个介入读锁流程的协程，因此需要唤醒一个等待写锁的阻塞队列的 goroutine.
		// 综合 RWMutex.readerCount 为负值，可以确定存在等待写锁的 goroutine
		runtime_Semrelease(&rw.writerSem, false, 1)
	}
}

// 写者加锁
func (rw *RWMutex) Lock() {
	if race.Enabled {
		_ = rw.w.state
		race.Disable()
	}
	// 并发写的互斥 限制多写者进入下边的逻辑
	rw.w.Lock()
	// 只要读锁的数量小于1<<30位,rw.readerCount值<0表示有写锁.  后续+不影响readerCount
	// 在写者到来前是否还存在读者
	r := atomic.AddInt32(&rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders
	// r!=0为有读锁,将读锁数转移到读等待数(之前存在的读者加到读等待锁),然后写锁阻塞
	if r != 0 && atomic.AddInt32(&rw.readerWait, r) != 0 {
		runtime_SemacquireMutex(&rw.writerSem, false, 0) // 写者阻塞, 等待唤醒
	}

	if race.Enabled {
		race.Enable()
		race.Acquire(unsafe.Pointer(&rw.readerSem))
		race.Acquire(unsafe.Pointer(&rw.writerSem))
	}
}


func (rw *RWMutex) TryLock() bool {
	if race.Enabled {
		_ = rw.w.state
		race.Disable()
	}
	if !rw.w.TryLock() {
		if race.Enabled {
			race.Enable()
		}
		return false
	}
	if !atomic.CompareAndSwapInt32(&rw.readerCount, 0, -rwmutexMaxReaders) {
		rw.w.Unlock()
		if race.Enabled {
			race.Enable()
		}
		return false
	}
	if race.Enabled {
		race.Enable()
		race.Acquire(unsafe.Pointer(&rw.readerSem))
		race.Acquire(unsafe.Pointer(&rw.writerSem))
	}
	return true
}

// 写锁解锁
func (rw *RWMutex) Unlock() {
	if race.Enabled {
		_ = rw.w.state
		race.Release(unsafe.Pointer(&rw.readerSem))
		race.Disable()
	}

	// tag: 写者解锁，readerCount加上之前扣减的
	r := atomic.AddInt32(&rw.readerCount, rwmutexMaxReaders)

	// 读者数大于rwmutexMaxReaders 要么当前 RWMutex 未上过写锁 要么读者数量已经超限报错
	if r >= rwmutexMaxReaders {
		race.Enable()
		fatal("sync: Unlock of unlocked RWMutex")
	}
	// 读者 在写锁取锁，然后解锁的期间到来
	for i := 0; i < int(r); i++ {
		// 写者解锁有义务唤醒，阻塞的读者 说明：竞争读锁的 goroutine 更具备优势
		runtime_Semrelease(&rw.readerSem, false, 0)
	}
	//解开 RWMutex 内置的互斥锁
	rw.w.Unlock()
	if race.Enabled {
		race.Enable()
	}
}

// RLocker returns a Locker interface that implements
// the Lock and Unlock methods by calling rw.RLock and rw.RUnlock.
func (rw *RWMutex) RLocker() Locker {
	return (*rlocker)(rw)
}

type rlocker RWMutex

func (r *rlocker) Lock()   { (*RWMutex)(r).RLock() }
func (r *rlocker) Unlock() { (*RWMutex)(r).RUnlock() }

```
# 条件变量 sync.Cond
``` go
var cond sync.Cond      //定义全局条件变量
func producer(out chan<-int,idx int){
	for {
		//先加锁
		cond.L.Lock()
		//判断缓冲区是否满
		for len(out) == cap(out){
			cond.Wait()    //1,zuse 2 shifangsuo 3 huanxingjiasuo
		}
		num:= rand.Intn(999)
		out<- num
		fmt.Println("生产者:",idx,"生产：", num)
		//访问公共区结束，并且打印结束，解锁
		cond.L.Unlock()
		//唤醒对端
		cond.Signal()
		time.Sleep(time.Millisecond*300)
	}
}

func consumer(in <-chan int,idx int){
	for {
		cond.L.Lock()
		//判断缓冲区是否为空
		for len(in)== 0{
			cond.Wait()
		}
		num := <-in
		 fmt.Println("消费者:",idx,"消费：",num)
		//访问公共区结束后，解锁
		cond.L.Unlock()  //锁的力度越小越好
		cond.Signal()
		 time.Sleep(time.Millisecond*300)
	}
}

func main(){
	rand.Seed(time.Now().UnixNano())
	product := make(chan int,5)
	//指定条件变量 使用的锁
	cond.L = new(sync.Mutex)//互斥锁初值为0，是未加锁状态

	for i:=0;i<5;i++{
		go producer(product,i+1)

	}
	for i:=0;i<5;i++{
		go consumer(product,i+1)
	}
	for{
		;
	}
}
```

# 信号量
- 信号量（Semaphore）是一种同步原语，用于实现多线程和多进程之间的同步和互斥。信号量的本质是一个整数计数器，通常用于限制对共享资源的访问数量。信号量的实现涉及到两个关键操作：wait（或称为P操作）和post（或称为V操作）。
  - 初始化：信号量在创建时需要进行初始化，通常将计数器设置为允许同时访问共享资源的最大数量。
  - Wait（P）操作：当一个线程或进程想要访问共享资源时，会执行wait操作。在wait操作中，信号量的计数器减1。如果计数器的值为负数，表示没有可用的资源，执行wait操作的线程/进程将被阻塞，直到有资源可用。
  - Post（V）操作：当一个线程或进程完成对共享资源的访问后，会执行post操作。在post操作中，信号量的计数器加1。如果计数器的值小于等于0，表示有等待的线程/进程，此时会唤醒一个被阻塞的线程/进程

# [semaphore 扩展库实现](https://www.jb51.net/article/257650.htm)
参照 golang.org/x/sync/semaphore
后续可以搬到博客

## 使用缓存通道模拟 信号量
- 使用 buffered channel 其实也可以模拟出来 n 个信号量的效果，但就不具备 semaphore Weighted 这套实现里面，一次获取多个资源的能力了。
```go
type Semaphore chan struct{}

func NewSemaphore(n int) Semaphore {
    return make(Semaphore, n)
}

func (s Semaphore) Wait() {
    s <- struct{}{}
}

func (s Semaphore) Signal() {
    <-s
}
```

# 资源
- [b站视频](https://www.bilibili.com/video/BV1kv4y157wj)

- [Golang 单机锁实现原理](https://mp.weixin.qq.com/s/5o0pR0RDaasKh4veXTctVg)