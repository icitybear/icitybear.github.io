---
title: "go包-限流（限频）-实时" #标题
date: 2024-07-12T14:40:10+08:00 #创建时间
lastmod: 2024-07-12T14:40:10+08:00 #更新时间
author: ["citybear"] #作者
categories: # 没有分类界面可以不填写
- tech
tags: # 标签
- go包
keywords: 
- 
description: "" #描述 每个文章内容前面的展示描述
weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序
slug: ""
draft: false # 是否为草稿
comments: true #是否展示评论 有自带的扩展成twikoo
showToc: true # 显示目录 文章侧边栏toc目录
TocOpen: true # 自动展开目录
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
disableShare: true # 底部不显示分享栏
showbreadcrumbs: true #顶部显示当前路径
cover:
    image: "" #图片路径：posts/tech/文章1/picture.png
    caption: "" #图片底部描述
    alt: ""
    relative: false

# reward: true # 打赏
mermaid: true #自己加的是否开启mermaid
---
流量控制Q 基本是 《微服务》和高并发系统设计的入门课，即便是在早期各种负载均衡和网络组件 （如nginx、iptable、TC）都有提供基 础的QPS限制能力，如今演进到微服务框架、<font color="red">Sentinel</font>、Service Mesh和Serverless都已经具备完备的配置化的限流的能力已经能够满足 大多数场景了，但如果我们<font color="red">在一些不以服务作为颗粒的方式可能就不太适用了，比如以下几个场景：</font>

1. 调用外部三方服务存在频率限制
2. 队列消费控速 。
   - 设置最大消费线程数、每次拉取消息条数拉取间隔时间 。
   - 这样能够能精准控制队列的处理频率吗？（有些主流MQ中间件SDK有实现匀速器，如RocketMQ，但是单点限流不能多消费者 分布式共享） 
3. 当被超过频率限制时执行一段兜底逻辑

漏桶、令牌桶等，他们的缺点是单一限流和无差别限流。此外，系统需要先做压测，拿到一个初始的限流参考值，超过这个值才启动限流机制

# 信号量 [semaphore 扩展库实现](https://www.jb51.net/article/257650.htm)
使用 buffered channel 其实也可以模拟出来 n 个信号量的效果，但就不具备 semaphore Weighted 这套实现里面，一次获取多个资源的能力了。
![alt text](image1.jpg)
- 利用channel也能模拟
{{< innerlink src="posts/tech/go18.md" >}}


# 漏桶 github.com/uber-go/ratelimit 
漏桶算法：业务先统一进入桶里，桶满了之后，会以我们预期的限流速率，一个个把在等待的业务漏出去，然后各个业务才开始执行 业务逻辑

``` go
func TestRateLimit(t *testing.T) {
    limiter := ratelimit.New(50) // 1.漏桶速率50

    size := 500
    data := generateData(size)

    var wg sync.WaitGroup
    startTime := time.Now()
    for i, item := range data {
        wg.Add(1)
        go func(idx int, obj any) {
            defer wg.Done()
            limiter.Take() // 2. 入桶待漏
            processed, err := process(obj)
            if err != nil {
                t.Logf("[%d] [ERROR] processed: %v, err: %v", idx, processed, err)
            } else {
                t.Logf("[%d] [OK] processed: %v", idx, processed)
            }
        }(i, item)
    }
    wg.Wait()
    endTime := time.Now()
    t.Logf("start: %v, end: %v, seconds: %v", startTime, endTime, endTime.Sub(startTime).Seconds())
}

```

# 令牌桶 golang.org/x/time/rate
- 漏桶的进一步优化
  - 容纳了 burst 个令牌，可以提供临时的突发份额。 如果不能容忍突发，漏桶更加合适。
  - <font color="red">速度 T token/秒, 容量最大为 Burst 个, 尝试取出 N 个 token, N <= burst剩余 token 不足 则等待</font>
- 令牌桶算法：在特定容量的桶里面装令牌，当令牌数量小于桶的容量时，会持续以我们预期的限流速率生产令牌；不管桶里面是不是 空的，业务都得等到拿到令牌，才能继续执行业务逻辑
- 业务通过令牌桶方式限速时，如果需要限制冷启动时的瞬时速率，需要留意把burst的值设置小一些
  - burst这个桶具备了缓冲作用，在冷启动时，由于burst的存在，初始的QPS会比实际预估的较大

- <font color="red">限流值和 take 数量相差较大，将会导致意料外的长时间阻塞</font>
  - 阻塞请求本身
  - 限流器内部长时间地持有锁，也会导致更新操作阻塞异常

比如限流 1KB/s，请求 10MB，下一个请求将阻塞 ~1000s。更新限流值也将在 1000s 后才能生效

``` go
import "golang.org/x/time/rate" // 需要import的rate库，其它import暂时忽略

// 生成0->X的数据集
func generateData(num int) []any {
    var data []any
    for i := 0; i < num; i++ {
        data = append(data, i)
    }
    return data
}

// 处理数据，数字*10
func process(obj any) (any, error) {
    integer, ok := obj.(int)
    if !ok {
        return nil, errors.New("invalid integer")
    }
    time.Sleep(1)
    nextInteger := integer * 10
    if integer%99 == 0 {
        return nextInteger, errors.New("not a happy number")
    }
    return nextInteger, nil
}

func TestRate(t *testing.T) {
    limit := rate.Limit(5) // QPS：5 基础速率
    burst := 25 // 桶容量25
    limiter := rate.NewLimiter(limit, burst) // 1. 初始化一个令牌生成速率为limit，容量为burst的令牌桶
    
    size := 50 // 数据量50
    data := generateData(size)

    var wg sync.WaitGroup // 工作组锁
    startTime := time.Now()
    for i, item := range data {
        wg.Add(1)
        go func(idx int, obj any) {
            defer wg.Done()
            // 2. Wait拿到令牌
            if err := limiter.Wait(context.Background()); err != nil {
                t.Logf("[%d] [EXCEPTION] wait err: %v", idx, err)
            }
            // 执行业务逻辑
            processed, err := process(obj)
            if err != nil {
                t.Logf("[%d] [ERROR] processed: %v, err: %v", idx, processed, err)
            } else {
                t.Logf("[%d] [OK] processed: %v", idx, processed)
            }
        }(i, item)
    }
    wg.Wait()
    endTime := time.Now()
    t.Logf("start: %v, end: %v, seconds: %v", startTime, endTime, endTime.Sub(startTime).Seconds())
}
```

- [Go 限流控制《滑动窗口&令牌桶》：time/rate、TokenLimit、PeriodLimit](https://blog.csdn.net/u011142688/article/details/126683615)
  - 保证原子性基于redis实现分布式令牌桶，lua脚本
  - go-zero提供的令牌桶当redis故障是会切换到内存令牌桶time/rate来降低影响，但是会影响限流的精准性

## 理解qps和初始化的容量，合理使用ctx
``` go

func TestTimeRate(t *testing.T) {

	num := rate.Every(time.Millisecond * 100) // 0.1=>每秒10个 100写成500每秒50个
	// num := rate.Limit(10)                // 10=>0.1（每秒10个） 20 => 0.2
	limiter := rate.NewLimiter(num, 5) // 1. 初始化一个令牌生成速率为limit，容量为burst的令牌桶
	// tag:容量为burst容量一开始就满了，然后下个时间频率继续产令牌
	timer := time.NewTimer(time.Second * 3) // 定时器 5秒的定时器 5s后通道收到消息
	quit := make(chan struct{})             // 通道
	defer timer.Stop()
	go func() {
		<-timer.C   // 定时器到期 定时器收到消息
		close(quit) // 通知子协程都关闭
	}()

	var allowed, denied int32
	var wait sync.WaitGroup
	cpuNum := runtime.NumCPU()
	fmt.Println(cpuNum) // 8核

	for i := 0; i < cpuNum; i++ {
		wait.Add(1)
		// 1秒能循环1万次
		go func() {
			
			for {
				select {
				// tag:接收外部关闭消息
				case <-quit:
					wait.Done()
					return
				default:
					ctx, cancel := context.WithTimeout(context.TODO(), time.Second) // 1s超时
					// 2. Wait拿到令牌
					err := limiter.Wait(ctx)
					if err == nil {
						// tag: 能证明初始化就有burst个， 令牌设置成1s1个，然后allowed是变量外部传入的 打印结果 0 1 2 3 0 5 6 7
						t.Logf("获取到令牌: allowed %v, Time: %v", allowed, time.Now().Format("2006-01-02 15:04:05.000")) //打印每个抢到的时间
						atomic.AddInt32(&allowed, 1)
					} else {
						//tag: 如果令牌产生太慢就会有N个这日志 ctx设置1秒超时 1s都有1万次 rate: Wait(n=1) would exceed context deadline
						t.Logf("未获取到令牌:denied %v, Time: %v, err: %s", denied, time.Now().Format("2006-01-02 15:04:05.000"), err.Error())
						fmt.Println(err)
						atomic.AddInt32(&denied, 1)
					}
					cancel()
				}
			}

		}()
	}

	wait.Wait()
	fmt.Printf("allowed: %d, denied: %d, qps: %d\n", allowed, denied, (allowed+denied)/10)
}

// 8
//rate_test.go:109: 获取到令牌: allowed 0, Time: 2024-08-07 18:29:34.213
//rate_test.go:109: 获取到令牌: allowed 1, Time: 2024-08-07 18:29:34.213
//rate_test.go:109: 获取到令牌: allowed 2, Time: 2024-08-07 18:29:34.213
//rate_test.go:109: 获取到令牌: allowed 3, Time: 2024-08-07 18:29:34.213
//rate_test.go:109: 获取到令牌: allowed 0, Time: 2024-08-07 18:29:34.213 //初始化的容量就是5个
//rate_test.go:109: 获取到令牌: allowed 5, Time: 2024-08-07 18:29:35.213 //然后频率设置1秒1个令牌
//rate_test.go:109: 获取到令牌: allowed 6, Time: 2024-08-07 18:29:36.213
//rate_test.go:109: 获取到令牌: allowed 7, Time: 2024-08-07 18:29:37.213
```

## 实战 控制第三方请求qps 
- 参照go18
``` go
// QqPromotionNormDayReportLoad 广告组每日报表-各种指标
func (q *Qq3ReportCase) QqPromotionNormDayReportLoad(ctx context.Context, startDate string) {
	bT := time.Now()
	log.Context(ctx).Infof("[QqPromotionNormDayReportLoad]: Run start:%+v", bT)
    // 1. 方便本地模拟跑数据
	// advertisers := make([]*models.QqAdvertiserListV3, 0)
	// advertisers = append(advertisers, &models.QqAdvertiserListV3{AdvertiserID: "33710528", MajordomoID: "33450643"})
	// advertisers = append(advertisers, &models.QqAdvertiserListV3{AdvertiserID: "34617211", MajordomoID: "33450643"})
	// 查询advertisers
	advertiserRepo := data.NewQqAdvertiserListV3Repo()
	advertisers, _ := advertiserRepo.RecordGetAll(ctx, &models.QqAdvertiserListV3ListParam{}, "advertiser_id,majordomo_id", "id asc")

	if len(advertisers) <= 0 {
		log.Context(ctx).Warnf("[QqPromotionNormDayReportLoad]#没有查询到广告主")
		return
	}

	// 令牌桶 2000 每分钟 如果是分布式就要考虑redis的lua脚本，如果api是全局也要考虑
	// rate.Every(time.Millisecond * 100) 1个的时间=》1ms*100 也就是每秒10个
	limit := rate.Limit(33)
	burst := 2000
	limiter := rate.NewLimiter(limit, burst) // 2. 限流器的最大事件频率和一次可以消费的最大令牌数
	wg := sync.WaitGroup{} // 工作组，等待所有goroutine都执行完毕
	// 3. tag: 1.通过信号量控制通知进行的最大并发 2.可以分页取广告主
	concurrent := semaphore.NewWeighted(5)
	for _, advertiserInfo := range advertisers {
		concurrent.Acquire(ctx, 1)
		wg.Add(1)
		log.Context(ctx).Infof("[QqPromotionNormDayReportLoad]#syncPullGdtAdGroupDayReport advertiser: %+v, majordomo: %+v", advertiserInfo.AdvertiserID, advertiserInfo.MajordomoID)
		go q.syncPullGdtAdGroupDayReport(ctx, advertiserInfo.AdvertiserID, startDate, &wg, limiter, concurrent)
	}

	wg.Wait()

	eT := time.Since(bT)
	log.Context(ctx).Infof("[QqPromotionNormDayReportLoad]: Run time:%+v", eT)
}

func (q *Qq3ReportCase) syncPullGdtAdGroupDayReport(ctx context.Context, advertiserId string, startDate string, wg *sync.WaitGroup, limiter *rate.Limiter, concurrent *semaphore.Weighted) {
    // tag: 每个子协程最好再见defer捕捉panic, 防止整个程序main协程panic
	defer func() {
		if err := recover(); err != nil {
			log.Context(ctx).Errorf("Runtime panic caught: %v\n", err)
		}
	}()
    
	defer concurrent.Release(1)
	defer wg.Done()

	page := 1
	pageSize := 100
	adgroupRepo := data.NewQqAdgroupDayReportRepo()

	for {
		// 4. 等待拿到令牌 发起请求
		err := limiter.WaitN(ctx, 1)
		if err != nil {
			log.Context(ctx).Warnf("[syncPullGdtAdGroupDayReport]#advertiserId:%s--err#%+v", advertiserId, err)
			break
		}
		log.Context(ctx).Infof("[syncPullGdtAdGroupDayReport]#advertiserId:%s--page:%d--time:%s", advertiserId, page, time.Now().Format("2006-01-02 15:04:05"))

		qqAdgroupInfo := q.queryAdGroupDayReport(ctx, advertiserId, startDate, startDate, page, pageSize)
		if len(qqAdgroupInfo.List) <= 0 {
			log.Context(ctx).Warnf("[syncPullGdtAdGroupDayReport]#advertiserId:%s, page:%d, list没有数据#%+v", advertiserId, page, qqAdgroupInfo)
			break
		}

		var unqMd5List []string
		var unqMd5MapInfo = make(map[string]response.Qq3PromotionDayRspDataItem, 0)
		// 5. 进行转换 建议所有三方接口返回的json 都用定义好的结构体进行解析接收，使用map时，因为类型断言会有问题（比如interger无法确认时int32还是int64， float32与float64）
		qqPromotionReportList := make([]response.Qq3PromotionDayRspDataItem, 0)
		mapstructure.Decode(qqAdgroupInfo.List, &qqPromotionReportList)

		for _, promotionReport := range qqPromotionReportList {

			adgroupIdStr := fmt.Sprintf("%v", promotionReport.AdgroupId)
			// strconv.FormatFloat(adgroupId, 'f', 0, 64)
			unqRemark := unit.ComputeMD5(fmt.Sprintf("%s%s%s", adgroupIdStr, "", promotionReport.Date))
			promotionReport.UnqRemark = unqRemark
			unqMd5MapInfo[unqRemark] = promotionReport

			unqMd5List = append(unqMd5List, unqRemark)
		}

		if len(unqMd5List) <= 0 {
			log.Context(ctx).Warnf("[syncPullGdtAdGroupDayReport]#advertiserId:%s, page:%d, 返回结构异常,list无合法字段字段#%+v", advertiserId, page, qqAdgroupInfo.List)
			break
		}

		// 6. tag: 查询是否已存在 获取主键id
		hasExistIdMap, err := adgroupRepo.GetUnqMd5Ids(ctx, unqMd5List)
		if err != nil {
			log.Context(ctx).Warnf("[syncPullGdtAdgroupList]#advertiserId:%s, page:%d, GetUnqMd5Ids db error#%+v", advertiserId, page, err)
		}

		err = adgroupRepo.BatchSaveQqAdGroupDayReport(ctx, hasExistIdMap, unqMd5MapInfo, advertiserId, "3")
		if err != nil {
			log.Context(ctx).Warnf("[syncPullGdtAdgroupList]#advertiserId:%s, page:%d, SaveQqAdGroupDayReport db error#%+v", advertiserId, page, err)
		}

		page++
	}

}
``` 
- 每次起协程 需要defer捕捉panic
- defer执行的时机, 禁止在循环中使用 defer 的处理

## [源码分析](https://blog.csdn.net/qq_29799655/article/details/128297954)
- reserveN 实现的
``` go
func (lim *Limiter) reserveN(t time.Time, n int, maxFutureReserve time.Duration) Reservation {
    // 获取全局锁
    // 意味着该限流器所有的请求都会争抢这个锁
    lim.mu.Lock()
    defer lim.mu.Unlock()
    ...
    // 处理 limit = Inf 和 0 的情况
    // limit=Inf 放行
    // limit=0，burst 满足则放行，否则不 ok
    ...

    // lazy 计算到目标时间 token 个数
    // 以当前的 limite 值 * 经过时间
    t, tokens := lim.advance(t)

    // 扣减请求的 N
    // Calculate the remaining number of tokens resulting from the request.
    tokens -= float64(n)

    // 如果为负，得等！计算等待时间
    // 注意：在此后，时间已经返回了。
    // 这意味着，无论是 Wait 还是 Reserve 后自行 sleep，
    // 这期间更新限流器限流值，不能更改 sleep 时间了，
    // 这可能导致带宽限流的长时间 sleep
    var waitDuration time.Duration
    if tokens < 0 {
        waitDuration = lim.limit.durationFromTokens(-tokens)
    }

    // Decide result
    ok := n <= lim.burst && waitDuration <= maxFutureReserve

    // Prepare reservation
    ...
    return r
}
```
- Wait/WaitN, Allow/AllowN, Reserve/ReserveN 实际上都是通过内部方法 
``` go
func (lim *Limiter) wait(ctx context.Context, n int, t time.Time, newTimer func(d time.Duration) (<-chan time.Time, func() bool, func())) error {
    ... 处理ctx，burst
    ... ctx 到期、N 大于 burst 报错
    ... limit 为 Inf 时直接返回通过

    // 使用 Reserve 判断
    r := lim.reserveN(t, n, waitLimit)
    if !r.ok {
        return fmt.Errorf("rate: Wait(n=%d) would exceed context deadline", n)
    }

    // ctx 和 timer 共同在 select 等待
    // 虽然此时未占用锁，但意味着不会接收 limiter 更新
    // Wait if necessary
    delay := r.DelayFrom(t)
    if delay == 0 {
        return nil
    }
    ch, stop, advance := newTimer(delay)
    defer stop()
    advance() // only has an effect when testing
    select {
    case <-ch:
        // We can proceed.
        return nil
    case <-ctx.Done():
        // Context was canceled before we could proceed.  Cancel the
        // reservation, which may permit other events to proceed sooner.
        r.Cancel()
        return ctx.Err()
    }
}
``` 
- SetLimit 会和请求共同争抢 mutex。改变 Limit/Burst 可能导致已经拿到 reserve 还未执行的请求限速不准。


``` go
func (lim *Limiter) SetLimit(newLimit Limit) {
    lim.SetLimitAt(time.Now(), newLimit)
}

func (lim *Limiter) SetLimitAt(t time.Time, newLimit Limit) {
    lim.mu.Lock()
    defer lim.mu.Unlock()

    t, tokens := lim.advance(t)

    lim.last = t
    lim.tokens = tokens
    lim.limit = newLimit
}
```
# 动态限流：sentinel-golang 限流和kratos的限流
{{< innerlink src="posts/tech/base6.md" >}}
